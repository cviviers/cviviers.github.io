<html lang="en">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport" shrink-to-fit=no">
    <meta content="portfolio website for Christiaan Viviers" name="description">
    <meta content="Chris Viviers https://github.com/cviviers" name="author">
    <title>Chris Viviers | Projects</title>

    <link href="img/favicon.ico" rel="shortcut icon"/>
    <link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@100;200;500&display=swap" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link href="css/bootstrap-grid.css" rel="stylesheet">
</head>




<body>
<div class="nav-header">
    <button onclick="dayNightToggle()">Toggle dark mode</button>
    <nav>
        <ul>
            <li><a href="index.html">Me</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="services.html">Services</a></li>
        </ul>
    </nav>
    </div>
<div class="container">
    <div class="row">
        <div class="center col-10 col-sm-10 col-lg-10 col-md-10 spacing">
            <h1>Projects</h1>
            <p class="title-desc center">A selection of projects I've worked on</p>
        </div>
    </div>
</div>

<div class="container-fluid">
    <div class="row">
        <div class="center col-10 col-sm-10 col-lg-8 col-md-8 spacing">
            
            <!-- Project 1 -->
            <div class="project-item">
                <h2 class="project-title">Synthetic Data Generation for Novel Object Detection</h2>
                <div class="project-meta">
                    <span class="project-date">2025</span> • 
                    <span class="project-tags">Generative AI, Few Shot Object Detection, Machine Learning, Jetson Orin</span>
                </div>
                
                <div class="project-images">
                    <img src="projects/purple/20251106_160936.jpg" alt="Project visualization" class="project-img">
                    <div class="project-image-grid">
                        <img src="projects/purple/20251106_164758.jpg" alt="Project detail 1" class="project-img-small">
                        <img src="projects/purple/pitch.png" alt="Project detail 2" class="project-img-small">
                    </div>
                </div>
                
                <div class="project-description">
                    <p>I developed a custom synthetic data generation pipeline to improve novel object detection performance in low-data scenarios. The solution won the Purple NECtar X Innovation in Defence (PN x IID) 2025 challenge. </p>
                    
                    <h3>Key Features</h3>
                    <ul class="project-list">
                        <li>Utilize open-source generative models (QWEN Image / Edit)</li>
                        <li>Optimized data flow for creating annotated objected detection datasets</li>
                        <li>Trained custom object detection models (cross-domain few-shot object detection) using synthetic data only</li>
                        <li>Deployed models on NVIDIA Jetson Orin for real-time inference on real-world scenarios</li>
                    </ul>
                    
                    <h3>Technical Details</h3>
                    <p>The synthetic data pipeline integrates open-source generative models, such as QWEN Image  Edit, to synthesize diverse objects and scene variations and automatically generate high-quality bounding-box annotations.
                        A modular data-flow architecture ensures efficient batch generation, post-processing, and dataset assembly tailored for few-shot, cross-domain object detection. 
                        Using only synthetic samples, I trained lightweight detection models optimized for transferability to real-world conditions and validated their performance on downstream tasks.
                        The final models were containerized and deployed on NVIDIA Jetson Orin devices, achieving real-time inference throughput under constrained GPU and memory resources.</p>
                </div>
                
                <div class="project-links">
                    <a class="external-element" href="https://www.linkedin.com/feed/update/urn:li:activity:7393574976555032576/">LinkedIn</a>
                </div>
                
                <hr class="project-divider">
            </div>
            
            <!-- Project 2 -->
            <div class="project-item">
                <h2 class="project-title">Foundation Model for Computed Tomography</h2>
                <div class="project-meta">
                    <span class="project-date">2025</span> • 
                    <span class="project-tags">Computer Vision, CT, Foundation Models</span>
                </div>
                
                <div class="project-images">
                    <img src="projects/spectre/methods_overview.jpg" alt="Robot navigation" class="project-img">
                    <div class="project-image-grid">
                        <img src="projects/spectre/DGX.jpeg" alt="Sensor setup" class="project-img-small">
                        <img  src="projects/spectre/segmentations.jpg" alt="Path planning" class="project-img-small">
                    </div>
                </div>
                
                <div class="project-description">
                    <p>Cris Claessens and I developed SPECTRE, a fully transformer-based foundation model for volumetric computed tomography (CT). Our Self-Supervised & Cross-Modal Pretraining for CT Representation Extraction (SPECTRE) approach utilizes
                    scalable 3D Vision Transformer architectures and modern self-supervised and vision–language pretraining strategies to learn general-purpose CT representations. Volumetric
                    CT poses unique challenges, such as extreme token scaling, geometric anisotropy, and weak or noisy clinical supervision, that make standard transformer and contrastive learning recipes ineffective out of the box. The framework jointly
                    optimizes a local transformer for high-resolution volumetric feature extraction and a global transformer for whole-scan context modeling, making large-scale 3D attention computationally tractable. Notably, SPECTRE is trained exclusively on openly available CT datasets, demonstrating that high-performing, generalizable representations can
                    be achieved without relying on private data. Pretraining combines DINO-style self-distillation with SigLIP-based vision–language alignment using paired radiology reports, yielding features that are both geometrically consistent and clinically meaningful. 
                    Across multiple CT benchmarks, SPECTRE consistently outperforms prior CT foundation models in both zero-shot and fine-tuned settings, establishing SPECTRE as a scalable, open, and fully transformer-based foundation model for 3D medical imaging.</p>
                    
                    <h3>Key Features</h3>
                    <ul class="project-list">
                        <li>First fully transformer-based foundation model for volumetric CT</li>
                        <li>Trained in a distributed fashion on NVidia DGX B200</li>
                        <li>Combines DINO-style self-distillation with SigLIP-based vision–language alignment</li>
                        <li>State-of-the-art performance on multiple CT benchmarks</li>
                    </ul>
                    
                </div>
                
                <div class="project-links">
                    <a class="external-element" href="https://www.tue.nl/en/news-and-events/news-overview/12-11-2025-super-powered-ai-from-eindhoven-helps-doctors-identify-cancer-and-other-diseases-more-quickly">TU/e News</a>
                    <a class="external-element" href="https://www.linkedin.com/feed/update/urn:li:activity:7395203880596221954/">Nvidia Post</a>
                    <a class="external-element" href="#">Paper Incoming</a>
                </div>
                
                <hr class="project-divider">
            </div>
            
            <!-- Project 3 -->
            <div class="project-item">
                <h2 class="project-title">Enhanced Computer Vision Methods for Cancer Detection and Precision Guidance in Medical Imaging</h2>
                <div class="project-meta">
                    <span class="project-date">2024</span> • 
                    <span class="project-tags">Computer Vision, Cancer Detection, Machine Learning</span>
                </div>
                
                <div class="project-images">
                    <img src="projects/thesis/cover.png" alt="Robot navigation" class="project-img">
                    <div class="project-image-grid">
                        <img src="projects/thesis/overview.png" alt="Sensor setup" class="project-img-small">
                        <img src="projects/thesis/defence.jpg" alt="Path planning" class="project-img-small">
                    </div>
                </div>
                
                <div class="project-description">
                    <p>During my PhD I developed advanced computer vision and deep learning methods to enhance cancer detection, improve segmentation robustness, quantify uncertainty, detect out-of-distribution data, and enable precise image-guided interventions across diverse medical imaging modalities. 
                        The thesis presents novel CADe systems for early pancreatic cancer detection using clinically meaningful secondary features; introduces improved probabilistic segmentation models using Normalizing Flows for reliable aleatoric uncertainty quantification; 
                        proposes an integrated framework for predicting pancreatic tumor resectability; advances OOD detection through wavelet-based and generative models; and delivers a general-purpose, real-time 6-DoF pose estimation method for X-ray–guided minimally invasive surgery. 
                        Collectively, these contributions push the boundaries of reliable, data-driven diagnostic and interventional support in modern medical imaging</p>
                    
                    <h3>Key Features</h3>
                    <ul class="project-list">
                        <li>Clinically informed early PDAC detection</li>
                        <li>Probabilistic segmentation with explicit uncertainty modeling</li>
                        <li>A reliable framework for predicting tumor resectability</li>
                        <li>Novel semantic and covariate OOD detection methodologies</li>
                        <li>A unified 6-DoF pose estimation model for image-guided surgery</li>
                    </ul>
                    
                    <h3>Skills obtained</h3>
                    <p>The PhD equipped me with a deep interdisciplinary skill set spanning advanced machine learning, medical imaging, and scientific research. I gained expertise in developing and evaluating complex deep learning models - including segmentation networks, probabilistic architectures, and generative models - 
                        for applications in uncertainty quantification, detecting out-of-distribution data, and designing real-time pose estimation systems. I built end-to-end pipelines for CT, MRI, X-ray, and RGB data, translated clinical knowledge into model features, 
                        handled large-scale datasets, and engineered reliable systems suitable for clinical environments. Along the way, I strengthened my abilities in experimental design, statistical analysis, scientific writing, and cross-disciplinary collaboration across technical and medical domains.</p>
                </div>
                
                <div class="project-links">
                    <a class="external-element" href="projects\thesis\CV_thesis_20241129.pdf">Download the thesis</a>
                    <a class="external-element" href="projects\thesis\thesis_cover.png">Enjoy the cover page in full resolution</a>
                    <a class="external-element" href="https://www.linkedin.com/posts/chrisviviers_phdcompleted-deeplearning-medicalimaging-activity-7281688275277209602-XpG7?utm_source=share&utm_medium=member_desktop&rcm=ACoAABxAjjcBSUG5KnHpHcHoeVaCQAIHSuDvJHU">LinkedIn</a>
                </div>
                
                <hr class="project-divider">
            </div>
            
            
        </div>
    </div>
</div>

<script src="js/load.js" type="text/javascript"></script>
</body>
</html>